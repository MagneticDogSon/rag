import pickle
import os

import streamlit as st
from streamlit_extras.add_vertical_space import add_vertical_space
from PyPDF2 import PdfFileReader, PdfFileWriter, PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.vectorstores import FAISS
from langchain_community.llms import LlamaCpp
from langchain.chains.question_answering import load_qa_chain
from langchain.callbacks import get_openai_callback

from langchain.chains import RetrievalQA
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
############################################################

st.set_page_config(page_title=" RAG Demo")




















###############################


with st.sidebar:
    #st.title('–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞')

    #uploaded_file = st.file_uploader('', type='pdf')
    #if uploaded_file:

       #path = os.path.join('Doc/', uploaded_file.name)
        #with open(path, "wb") as f:
            #f.write(uploaded_file.getvalue())


    # with st.spinner ('–ü–æ–¥–æ–∂–¥–∏—Ç–µ...'):
    #    time.sleep (100)
    # st.success('–ó–∞–≥—Ä—É–∂–µ–Ω–æ!')

    st.divider()
    st.title('–ù–∞—Å—Ç—Ä–æ–π–∫–∏')

    st.title('–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞')

    chunk_size = st.slider('–†–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤', 0, 1000, 500)
    chunk_overlap = st.slider('–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ', 0, 500, 50)

    fragments_size = st.slider('–ö–æ–ª-–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞', 0, 10, 3)
    st.divider()
    st.title('–ú–æ–¥–µ–ª—å')

    top_p = st.slider('Top-p', 0.0, 1.0, 0.4)
    top_k = st.slider('Top-k', 0, 100, 10)
    temp = st.slider('Temp', 0.0, 1.0, 0.1)
    st.divider()

###############################################

llm = LlamaCpp(model_path="model/model-q4_K.gguf",
        temperature = temp,
        top_p=top_p,
        top_k=top_k,

        streaming =True,
        n_gpu_layers=100,
        n_batch=8,
        n_ctx=2000,
        n_parts=1,
        verbose=True
                    )


def main():
    st.title("üìÑRAG Demo")
    st.header("–ß–∞—Ç —Å –í–∞—à–∏–º PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–º")

    # upload a your pdf file
    pdf = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–π —Ñ–∞–π–ª", type='pdf')
    st.write("----------")

    if pdf is not None:
        pdf_reader = PdfReader(pdf)

        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()

        # langchain_textspliter
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
            length_function=len
        )

        chunks = text_splitter.split_text(text=text)

        # store pdf name
        store_name = pdf.name[:-4]

        if os.path.exists(f"{store_name}.pkl"):
            with open(f"{store_name}.pkl", "rb") as f:
                vectorstore = pickle.load(f)
            # st.write("Already, Embeddings loaded from the your folder (disks)")
        else:

            embeddings = SentenceTransformerEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2")

            # Store the chunks part in db (vector)
            vectorstore = FAISS.from_texts(chunks,  embedding=embeddings)

            with open(f"{store_name}.pkl", "wb") as f:
                pickle.dump(vectorstore, f)



        query = st.chat_input("–ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É")
        # st.write(query)

        if query:
            doc = vectorstore.similarity_search(query=query, k=fragments_size)

            qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=vectorstore.as_retriever() )

            with get_openai_callback() as cb:
                response = qa.run(input_documents=doc, question=query)
                print(cb)
            st.write(response)


if __name__ == "__main__":
    main()





